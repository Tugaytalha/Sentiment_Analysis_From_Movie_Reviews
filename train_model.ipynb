{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model\n",
    "In this notebook, we will create and train a model to predict the sentiment of a movie review."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8802e2c3d3461f2c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\mukoi\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keras_nlp.models import Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:09:07.780938300Z",
     "start_time": "2024-06-14T12:08:58.772792400Z"
    }
   },
   "id": "dffd49ff42af3d31"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:09:09.515826800Z",
     "start_time": "2024-06-14T12:09:07.784453Z"
    }
   },
   "id": "3402fc6fce75a799"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/preprocessed_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:09:10.106975400Z",
     "start_time": "2024-06-14T12:09:09.516827900Z"
    }
   },
   "id": "1a3027cf728afbb8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   anger  boredom  empty  excitement  amusement  joy  disgust  love  neutral  \\\n0      0        0      1           0          0    0        0     0        0   \n1      0        0      0           0          0    0        0     0        0   \n2      0        0      0           0          0    0        0     0        0   \n3      0        0      0           1          0    0        0     0        0   \n4      0        0      0           0          0    0        0     0        1   \n\n   relief  ...  disappointment  gratitude  grief  pride  curiosity  optimism  \\\n0       0  ...               0          0      0      0          0         0   \n1       0  ...               0          0      0      0          0         0   \n2       0  ...               0          0      0      0          0         0   \n3       0  ...               0          0      0      0          0         0   \n4       0  ...               0          0      0      0          0         0   \n\n   annoyance  approval  remorse  admiration  \n0          0         0        0           0  \n1          0         0        0           0  \n2          0         0        0           0  \n3          0         0        0           0  \n4          0         0        0           0  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>anger</th>\n      <th>boredom</th>\n      <th>empty</th>\n      <th>excitement</th>\n      <th>amusement</th>\n      <th>joy</th>\n      <th>disgust</th>\n      <th>love</th>\n      <th>neutral</th>\n      <th>relief</th>\n      <th>...</th>\n      <th>disappointment</th>\n      <th>gratitude</th>\n      <th>grief</th>\n      <th>pride</th>\n      <th>curiosity</th>\n      <th>optimism</th>\n      <th>annoyance</th>\n      <th>approval</th>\n      <th>remorse</th>\n      <th>admiration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['text']).head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:09:15.306334700Z",
     "start_time": "2024-06-14T12:09:15.234193700Z"
    }
   },
   "id": "d2cedbb95cdb8890"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_new = df.drop(columns=['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:09:17.193359900Z",
     "start_time": "2024-06-14T12:09:17.137423800Z"
    }
   },
   "id": "3cf6e892b6b72790"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "anger              8194\nboredom             179\nempty               827\nexcitement         6388\namusement         11021\njoy               13192\ndisgust            6624\nlove              12033\nneutral           63936\nrelief             2815\nsadness           11923\nsurprise           7701\nnervousness       10269\nconfusion          7359\ndesire             3817\ndisapproval       11424\nembarrassment      2476\ncaring             5999\nrealization        8785\nfear               3197\ndisappointment     8469\ngratitude         11625\ngrief               673\npride              1302\ncuriosity          9692\noptimism           8715\nannoyance         13618\napproval          17620\nremorse            2525\nadmiration        17131\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find frequency of easch sentiment\n",
    "df_new.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:09:17.902567100Z",
     "start_time": "2024-06-14T12:09:17.834203900Z"
    }
   },
   "id": "b7c9ce478ff84959"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df_new, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TextVectorization layer\n",
    "max_features = 5000  # Maximum number of words to consider\n",
    "sequence_length = 28  # Maximum length of a sequence\n",
    "\n",
    "# Ensure X_train and X_test are of type str\n",
    "X_train = X_train.astype(str)\n",
    "X_test = X_test.astype(str)\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int', # float?\n",
    "    output_sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "# Adapt the vectorize layer to the training data\n",
    "vectorize_layer.adapt(X_train.values)\n",
    "\n",
    "# Vectorize the training and testing data\n",
    "X_train_vectorized = vectorize_layer(X_train.values)\n",
    "X_test_vectorized = vectorize_layer(X_test.values)\n",
    "\n",
    "# Convert y_train and y_test to numpy arrays\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:14:09.783681400Z",
     "start_time": "2024-06-14T12:13:56.266163700Z"
    }
   },
   "id": "d1edbe4f99ca0f85"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199154/199154 [00:00<00:00, 1095583.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "28"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find longest review\n",
    "max_len = 0\n",
    "for review in tqdm(X_train.values):\n",
    "    max_len = max(max_len, len(review.split()))\n",
    "max_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:14:09.985314Z",
     "start_time": "2024-06-14T12:14:09.785680800Z"
    }
   },
   "id": "cf1d8b9108594"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(28,), dtype=int64, numpy=\narray([   2,   16,    6, 1183,   87,  522,  259,    1,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0], dtype=int64)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#llok up x_train vector\n",
    "X_train_vectorized[125236]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:14:10.040003900Z",
     "start_time": "2024-06-14T12:14:09.988317900Z"
    }
   },
   "id": "3596093aa5aaf441"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "6224/6224 [==============================] - 23s 4ms/step - loss: 3.8951 - accuracy: 0.2535 - val_loss: 3.4760 - val_accuracy: 0.2560\n",
      "Epoch 2/4\n",
      "6224/6224 [==============================] - 22s 3ms/step - loss: 3.4709 - accuracy: 0.2570 - val_loss: 3.4776 - val_accuracy: 0.2560\n",
      "Epoch 3/4\n",
      "6224/6224 [==============================] - 22s 4ms/step - loss: 3.4719 - accuracy: 0.2570 - val_loss: 3.4789 - val_accuracy: 0.2560\n",
      "Epoch 4/4\n",
      "6224/6224 [==============================] - 24s 4ms/step - loss: 3.4725 - accuracy: 0.2570 - val_loss: 3.4788 - val_accuracy: 0.2560\n",
      "1556/1556 [==============================] - 5s 3ms/step - loss: 3.4788 - accuracy: 0.2560\n",
      "Test Loss: 3.4787793159484863\n",
      "Test Accuracy: 0.2559601664543152\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_vectorized, y_train, epochs=4, batch_size=32, validation_data=(X_test_vectorized, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_vectorized, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:24:36.045219Z",
     "start_time": "2024-06-14T12:23:00.380793900Z"
    }
   },
   "id": "f48f4118065c45b4"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7780/7780 [==============================] - 26s 3ms/step - loss: 3.4739 - accuracy: 0.2568\n",
      "Epoch 2/4\n",
      "7780/7780 [==============================] - 25s 3ms/step - loss: 3.4741 - accuracy: 0.2568\n",
      "Epoch 3/4\n",
      "7780/7780 [==============================] - 24s 3ms/step - loss: 3.4743 - accuracy: 0.2568\n",
      "Epoch 4/4\n",
      "7780/7780 [==============================] - 24s 3ms/step - loss: 3.4746 - accuracy: 0.2568\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20b2bb67880>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with whole dataset\n",
    "\n",
    "# Ensure x is of type string\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# Vectorize the whole dataset\n",
    "X_vectorized = vectorize_layer(df['text'].values)\n",
    "\n",
    "\n",
    "# Convert y to numpy arrays\n",
    "y = df_new.to_numpy()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_vectorized, y, epochs=4, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:30:51.877241900Z",
     "start_time": "2024-06-14T12:29:13.094871300Z"
    }
   },
   "id": "8dc0501b27ab69a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save the model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e7afede39f60347"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/sentiment_model\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Save the model\n",
    "save_model(model, 'models/sentiment_model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:31:27.711941800Z",
     "start_time": "2024-06-14T12:31:26.895160700Z"
    }
   },
   "id": "2b47d53dff87150f"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.10.1\n",
      "Keras version: 2.10.0\n",
      "Keras NLP version: 0.13.0.dev2024061303\n",
      "Numpy version: 1.26.4\n",
      "Pandas version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "# Print versions \n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "print(f'Keras version: {tf.keras.__version__}')\n",
    "print(f'Keras NLP version: {keras_nlp.__version__}')\n",
    "print(f'Numpy version: {np.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T12:31:28.325171900Z",
     "start_time": "2024-06-14T12:31:28.306171600Z"
    }
   },
   "id": "ae3830ab046809be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ad6c8ad437d7992"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
